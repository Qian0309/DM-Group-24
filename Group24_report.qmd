---
title: "IB9HP0 Data Management"
author: "Group 24"
output: pdf_document
number_sections: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

install.packages("RSQLite")
install.packages("dplyr")
install.packages("ggplot2")
install.packages("knitr")

library(knitr)
library(RSQLite)
library(dplyr)
library(ggplot2)
```

# Project Introduction

In our comprehensive project, we are aimed at creating a e-commerce database, focusing on IT products within the United Kingdom. Our project is divided into four pivotal stages, each contributing to the development and understanding of our e-commerce platform. 

# Part 1: Database Design and Implementation

## Task 1.1: E-R Diagram Design and Relationship Sets

In this report, we assume that the E-commerce platform primarily sells IT products within the UK and lacks an international shipment policy. Additionally, the company’s policy dictates that only be promoted once a year. Each "Product_ID" is determined by its "Supplier_ID," indicating that a supplier can only assign one "Product_ID" to each product. Furthermore, the E-commerce company collects payments and distributes them to suppliers later. There are 7 entities:

1)  Buyer: Represents the customers who create an account to place orders on the online shopping platform.

2)  Supplier: Represents the sellers who create an account to sell products on the platform

3)  Product: Represents the set of products available for purchase on the platform.

4)  Transaction: Represents product orders placed by customers.

5)  Promotion: Represents product promotions to attract willing customers.

6)  Shipper: Represents shipper information.

7)  Reviews: Represents the reviews made by the customer once the product is received.

The Entity-Relationship (E-R) diagram for our e-commerce database before normalisation is shown below:

![](Figures\Screenshots\ERD\ERD_before_normalization.png){fig-align="center"}

## Task 1.2: SQL Database Schema Creation

The conceptual schema outlined in Section 1.1 is converted into a logical schema after normalisation, using the following steps:

1NF: Multi-valued attributes include 'Buyer_Address' in the Buyer entity, 'Supplier_Address' in the Supplier entity, and 'Dimensions' in the Product entity that must be normalized. To address this, a separate Address table is created that stores address information with attributes that include address_id, house_number, house_name, street, city, county, and post_code. The Address entity is then linked to the Buyer and Supplier entities using referential keys; i.e., address_id serves as a foreign key in both Supplier and Buyer entities with a 1:1 cardinality. Similarly, dimensions are created as a separate entity and linked to the Product table with a 1:1 cardinality.

2NF: The Product and Buyer entities have an M:N relationship, which violates 2NF due to functional dependencies where many products can be bought by a single buyer and vice versa, creating duplicate entries of the primary key attribute in each table. To resolve this, a relationship table called 'order_details' is created, with product_id and buyer_id compositely stored as a primary key, and 'order_id' as the primary key of the order_details table.

3NF: The Logical Schema is designed to include only attributes that are directly dependent on the primary key of their respective table, with no transitive dependencies.

### Conceputual E-R Diaram of the Database after Normalisation

![](Figures\Screenshots\ERD\ERD_after_normalization.png){fig-align="center"}

### Logical Schema of the Database after Normalisation

* product(product _id, product _name, product _description, weight, price, promotion_id, dimension_id , supplier_id) 

* promotion(promotion_id, promotion_type, start_date, end_date, status) 

* buyer(buyer_id, first_name, last_name, date_of_birth, address_id) 

*supplier(Supplier_ID, Supplier_Name, Supplier_Type, Contract_Type, Number_of_year_of_association, address_id) 

* review(review_id, review_score, review_description, product_id, buyer_id) 

*payment(payment_id, payment_type, payment_amount, installment_number, order_id) 

* shipper(Shipper_ID, Shipper_Name, Service, Fixed Price, Cost_per_mile) 

* order_details(order_id, product_id, buyer_id, supplier_id, order_dates, shipper_id) 

* address(address_id, house_number, house_name, street, city, county, post_code) 

* dimension(Dimension_ID, Length, Width, Height) 

### Relationship Sets after Normalisation

We've conceptualised 12 relationship sets to illustrate how different entities within our e-commerce database interact and connect with one another.

1)  Buyer and Address (1:1):

![](Figures\Screenshots\relationship_set\buyer_address(1_1).png){fig-align="center"}

Indicates that each buyer has one address, and each address is associated with one buyer.

2)  Buyer and Order Details (1:N):

![](Figures\Screenshots\relationship_set\buyer_order(1_n).png){fig-align="center"}

Indicating a buyer can place multiple orders, with each 'order detail' linked to a single 'buyer'.

3)  Buyer and Reviews (1:N):

![](Figures\Screenshots\relationship_set\buyer_review(1_n).png){fig-align="center"}

Meaning a buyer can submit multiple reviews, with each review associated with that buyer.

4)  Order Details and Payment (1:N):

![](Figures\Screenshots\relationship_set\order_payment(1_n).png){fig-align="center"}

Meaning each order detail can involve multiple transactions, with each transaction corresponding to a specific order detail.

5)  Product to Dimension (1:1):

![](Figures\Screenshots\relationship_set\product_dimension(1_1).png){fig-align="center"}

Indicating each product has a unique set of dimensions, with each set of dimensions tied to a single product.

6)  Product to Order Details (1:N):

![](Figures\Screenshots\relationship_set\product_order(1_n).png){fig-align="center"}

Meaning that one product can be present in many order details. Conversely, each order detail is associated with only one product, indicating a specific product is selected for each order.

7)  Product to Promotion (N:1):

![](Figures\Screenshots\relationship_set\Product_Promotion(n_1).png){fig-align="center"}

Indicating that multiple products can be part of the same promotion. Conversely, each promotion can apply to multiple products.

8)  Product to Review (1:N):

![](Figures\Screenshots\relationship_set\Product_Review(1_n).png){fig-align="center"}

Showing that each product can have multiple reviews written about it. Conversely, each review is associated with one product, indicating that customers’ feedback is specific to a particular product

9)  Supplier and Order Details (1:N):

![](Figures\Screenshots\relationship_set\shipper_order(1_n).png){fig-align="center"}

Showing that a single supplier can be connected to multiple order details, with each order detail relating to only one supplier.

10) Supplier and Address (1:1):

![](Figures\Screenshots\relationship_set\supplier_address(1_1).png){fig-align="center"}

Each supplier is tied to a single address, and each address is linked to a specific supplier

11) Supplier and Order Details (1:N):

![](Figures\Screenshots\relationship_set\supplier_order(1_n).png){fig-align="center"}

Showing that a single supplier can be connected to multiple order details, with each order detail relating to only one supplier.

12) Supplier and Product (1:N):

![](Figures\Screenshots\relationship_set\supplier_product(1_n).png){fig-align="center"}

Indicating that a supplier sells many products. One supplier can be linked to multiple 'product' entities.

### Physical Schema of the Database

Now, we can translate the E-R diagram into a functional SQL database schema (normalised to up to 3NF), define tables with appropriate data types, constraints, primary and foreign keys.

#### Table Description for Promotions

```{r}
# Define the table data
promotion_table <- data.frame(
  `Field Name` = c("promotion_id", "promotion_type", "start_date", "end_date", "status"),
  `Data Type` = c("VARCHAR(50)", "VARCHAR(50)", "DATE", "DATE", "VARCHAR(50)"),
  `Constraints` = c("PRIMARY KEY", "", "", "", ""),
  `Description` = c("Unique identifier for promotion", "Type of promotion", "Promotion start date", "Promotion end date", "Status of the promotion")
)

# Create the table
kable(promotion_table, caption = "Table Description for Promotions", align = 'l')
```

Indexing in databases, such as on the promotion_id field of a Promotion table, speeds up data retrieval by maintaining a separate, efficient data structure (like a B-tree) that maps keys to their respective rows in the table. This automatic indexing on primary keys as the first column allows for quick searches, insertions, and ensures uniqueness, enhancing query performance significantly. Indexing foreign key columns as the second key is crucial for enhancing the performance of join operations between tables

For other columns without explicit indexing, queries that search or filter by these fields may perform a full table scan, which is slower.

#### Table Description for Shippers

```{r}
# Define the table data for the shipper table
shipper_table <- data.frame(
  `Field Name` = c("shipper_id", "shipper_name", "service", "fixed_price", "cost_per_mile"),
  `Data Type` = c("VARCHAR(50)", "VARCHAR(50)", "VARCHAR(100)", "DOUBLE", "DOUBLE"),
  `Constraints` = c("PRIMARY KEY", "", "", "", ""),
  `Description` = c("Unique identifier for the shipper", 
                    "Name of the shipper", 
                    "Type of service offered by the shipper", 
                    "Fixed price for the service", 
                    "Cost per mile for the service")
)

# Create the table
kable(shipper_table, caption = "Table Description for Shippers", align = 'l')
```

#### Table Description for Address

```{r}

address_table <- data.frame(
  `Field Name` = c("address_id", "house_number", "house_name", "street", "city", "county", "post_code"),
  `Data Type` = c("VARCHAR(50)", "INT", "VARCHAR(50)", "VARCHAR(50)", "VARCHAR(20)", "VARCHAR(20)", "VARCHAR(10)"),
  `Constraints` = c("PRIMARY KEY", "", "", "", "NOT NULL", "", ""),
  `Description` = c("Unique identifier for the address", 
                    "Number of the house", 
                    "Name of the house if applicable", 
                    "Street name", 
                    "City name", 
                    "County name", 
                    "Postal code of the address")
)

# Create the table
kable(address_table, caption = "Table Description for Addresses", align = 'l')

```

#### Table Description for Dimensions

```{r}
# Define the table data for the dimension table
dimension_table <- data.frame(
  `Field Name` = c("dimension_id", "length", "width", "height"),
  `Data Type` = c("VARCHAR(50)", "DOUBLE", "DOUBLE", "DOUBLE"),
  `Constraints` = c("PRIMARY KEY", "", "", ""),
  `Description` = c("Unique identifier for the dimension record", 
                    "Length measurement", 
                    "Width measurement", 
                    "Height measurement")
)

# Create the table
kable(dimension_table, caption = "Table Description for Dimensions", align = 'l')

```

#### Table Description for Buyers

```{r}
buyer_table <- data.frame(
  `Field Name` = c("buyer_id", "first_name", "last_name", "date_of_birth", "address_id"),
  `Data Type` = c("VARCHAR(50)", "VARCHAR(250)", "VARCHAR(250)", "DATE", "VARCHAR(50)"),
  `Constraints` = c("PRIMARY KEY", "NOT NULL", "", "", "NOT NULL, FOREIGN KEY references address(address_id)"),
  `Description` = c("Unique identifier for the buyer", 
                    "First name of the buyer. Mandatory field.", 
                    "Last name of the buyer", 
                    "Date of birth of the buyer", 
                    "Reference to the buyer's address, must exist in the `address` table. This field is mandatory and establishes a foreign key relationship with the `address` table.")
)

# Create the table
kable(buyer_table, caption = "Table Description for Buyers", align = 'l')

```

#### Table Description for Suppliers

```{r}
# Load the knitr package for kable()

supplier_table <- data.frame(
  `Field Name` = c("supplier_id", "supplier_type", "contract_type", "number_of_year_of_association", "supplier_name", "address_id"),
  `Data Type` = c("VARCHAR(50)", "VARCHAR(250)", "VARCHAR(250)", "INT", "VARCHAR(50)", "VARCHAR(50)"),
  `Constraints` = c("PRIMARY KEY", "", "", "", "", "NOT NULL, FOREIGN KEY references address(address_id)"),
  `Description` = c("Unique identifier for the supplier", 
                    "Type of supplier (e.g., goods, services)", 
                    "Type of contract with the supplier", 
                    "Number of years the supplier has been associated with", 
                    "Name of the supplier", 
                    "Reference to the supplier's address, must exist in the `address` table. This field is mandatory and establishes a foreign key relationship with the `address` table.")
)

# Create the table
kable(supplier_table, caption = "Table Description for Suppliers", align = 'l')

```

#### Table Description for Products

```{r}
product_table <- data.frame(
  `Field Name` = c("product_id", "product_name", "product_description", "weight", "price", "promotion_id", "supplier_id", "dimension_id"),
  `Data Type` = c("VARCHAR(50)", "VARCHAR(250)", "VARCHAR(250)", "DOUBLE", "DOUBLE", "VARCHAR(50)", "VARCHAR(50)", "VARCHAR(50)"),
  `Constraints` = c("PRIMARY KEY", "", "", "", "", "NOT NULL, FOREIGN KEY references promotion(promotion_id)", "NOT NULL, FOREIGN KEY references supplier(supplier_id)", "NOT NULL, FOREIGN KEY references dimension(dimension_id)"),
  `Description` = c("Unique identifier for the product", 
                    "Name of the product", 
                    "Description of the product", 
                    "Weight of the product", 
                    "Price of the product", 
                    "Associated promotion ID, linking to the promotion table", 
                    "Associated supplier ID, linking to the supplier table", 
                    "Associated dimension ID, linking to the dimension table")
)

kable(product_table, caption = "Table Description for Products", align = 'l')

```

#### Table Description for Reviews

```{r}
review_table <- data.frame(
  `Field Name` = c("review_id", "buyer_id", "product_id", "review_score", "review_description"),
  `Data Type` = c("VARCHAR(50)", "VARCHAR(250)", "VARCHAR(250)", "DOUBLE", "VARCHAR(250)"),
  `Constraints` = c("PRIMARY KEY", "NOT NULL, FOREIGN KEY references buyer(buyer_id)", "NOT NULL, FOREIGN KEY references product(product_id)", "", ""),
  `Description` = c("Unique identifier for the review", 
                    "Associated buyer ID, linking to the buyer table", 
                    "Associated product ID, linking to the product table", 
                    "Numerical score of the review", 
                    "Textual description of the review")
)

kable(review_table, caption = "Table Description for Reviews", align = 'l')
```

#### Table Description for Order Details

```{r}
# Define the table data for the order_details table, including foreign key details within the table
order_details_table <- data.frame(
  `Field Name` = c("order_id", "product_id", "buyer_id", "supplier_id", "order_dates", "shipper_id"),
  `Data Type` = c("VARCHAR(50)", "VARCHAR(50)", "VARCHAR(50)", "VARCHAR(50)", "DATE", "VARCHAR(50)"),
  `Constraints` = c("PRIMARY KEY", "NOT NULL, FOREIGN KEY references product(product_id)", "NOT NULL, FOREIGN KEY references buyer(buyer_id)", "NOT NULL, FOREIGN KEY references supplier(supplier_id)", "", "NOT NULL, FOREIGN KEY references shipper(shipper_id)"),
  `Description` = c("Unique identifier for the order", 
                    "Associated product ID, linking to the product table", 
                    "Associated buyer ID, linking to the buyer table", 
                    "Associated supplier ID, linking to the supplier table", 
                    "Date of the order", 
                    "Associated shipper ID, linking to the shipper table")
)

kable(order_details_table, caption = "Table Description for Order Details", align = 'l')

```

#### Table Description for Payments

```{r}
payment_table <- data.frame(
  `Field Name` = c("payment_id", "payment_type", "payment_amount", "installment_number", "order_id"),
  `Data Type` = c("VARCHAR(50)", "VARCHAR(250)", "DOUBLE", "INT", "VARCHAR(50)"),
  `Constraints` = c("PRIMARY KEY", "", "", "", "NOT NULL, FOREIGN KEY references order_details(order_id)"),
  `Description` = c("Unique identifier for the payment", 
                    "Type of payment (e.g., credit card, PayPal)", 
                    "Total amount of the payment", 
                    "If applicable, the number of the installment", 
                    "Associated order ID, linking to the order_details table")
)
kable(payment_table, caption = "Table Description for Payments", align = 'l')
```

# Part 2: Data Generation and Management

## Task 2.1: Synthetic Data Generation

In the process of synthetic data generation, we use a combination of R, Mockaroo, and Excel to simulate a dataset that closely mimics real-world scenarios. Our dataset consists of 10 distinct entities that represent all the components in our system.

Mockaroo: For several entities we use Mockaroo to create data such as addresses, emails, and names.

R studios: We use R scripts to simulate the data distributions, especially in product, promotion, all the ID’s, and date related attributes, we wanted to make sure that the synthetic data reflects realistic variability and complexity.

Excel: After we imported the data from R and mockaroo, we combined the foreign keys. We use ‘Randbwteen’ features to ensure that the inter-entity relationships are accurately represented.

## Task 2.2: Data Import and Quality Assurance

The synthetic data, generated in .csv format, is imported. The data undergoes various integrity and validation checks, detailed below:

### Data Integrity:

1) Primary Key fields:

No NA/NULL values are allowed in the primary key attributes of any entities. The primary key ID must follow the format specified in Section 2.1.

2) Date fields:

No future dates should appear in any date field. This includes the Date of Birth of buyers, Promotion start and end dates, and Order dates.

3) Product entity:

The weight of the product must not exceed 100 pounds

4) Promotion entity:

The end date of a promotion must be later than its start date.

5) Review entity:

Review scores must not exceed 10.

6) Address entity:

Length of postcode should be only 5 or 6 characters in accordance with postcode of UK residents.

7) Dimension entity:

The Length, Width, and Height of a product must not exceed 150 cm.

8) Non-Negativity:

All numeric attributes of float or integer type must not have negative values. This includes Weight, Price, Years of Association, Review Score, Payment Value, Installment Number, Fixed Price, Cost per Mile, Length, Width, Height, and House Number.

### Referential Integrity :

Referential integrity checks are conducted for all relationships discussed in Section 1.1. For example, in the Product to Review (1:N) relationship, the Review entity's Product_ID, serving as a foreign key, indicates a specific product's review in the E-commerce system. Referential integrity ensures no review is entered for a product not present in the system. To validate, unique Product_ID keys from the Review table are compared with those from the Product table; the difference should be NULL or 0. A non-zero value indicates the presence of a Product_ID in the Review table that doesn't match any in the Product table, violating referential integrity. Such records are removed from the Review table.

# Part 3: Data Pipeline Generation

## Task 3.1: GitHub Repository and Workflow Setup

![](Figures\Screenshots\GitHub_related\GitHub_Repo.png){fig-align="center"}

To allow group members to collaborate on the project simultaneously we have adopted the use of a remote repository on GitHub. This online platform serves as a centralised storage for our project's history, enabling efficient management and version control.

![](Figures\Screenshots\GitHub_related\repo_url.png){fig-align="center"}
Integrating our project with Posit Cloud, we used the HTTPS clone URL from GitHub to establish a connection between our local and remote repositories directly within Posit Cloud. This integration streamlined our workflow by providing a centralised platform for development, enabling efficient access and management of the project's codebase.

![](Figures\Screenshots\GitHub_related\commit_push_pull.png){fig-align="center"}
To streamline our project management and enhance version control among team members, we utilised commit, push, and pull operations effectively. By committing changes before pushing, we enabled team members to save the state of our project at specific points following any modifications made in our local repositories. This process not only enables detailed tracking of who made specific changes and why, but also ensures that each contribution is reviewed before being shared with the team.

Pushing these commits to the remote repository then publishes each member's contributions, ensuring everyone is working on the most updated version. Regularly pulling updates from the remote repository is crucial for keeping our local copies current, significantly reducing the likelihood of merge conflicts between the local and remote version after changes are made.

![](Figures\Screenshots\GitHub_related\working_log.png){fig-align="center"}
These practices have collectively created a robust collaborative environment, significantly boosting our productivity and streamlining the project's progression.

## Task 3.2: GitHub Actions for Continuous Integration

GitHub Workflows automate processes within a repository using YAML files. We started by creating a `.github/workflows/` directory to house our workflow files. Then, we added a file named "ETL workflow for group24" within this directory to outline our specific automated tasks, focusing on the Extract, Transform, Load (ETL) processes crucial to our project's data handling needs, enhancing efficiency.

The workflow of our project is shown in the screenshot below

![](Figures\Screenshots\GitHub_related\workflow.png){fig-align="center"}

In this phase of configuring our GitHub Workflow, we set the trigger condition to activate on every push event to the repository. This configuration ensures that any time changes are pushed or a pull request is merged, the workflow initiates automatically. Following a thorough review of the code to confirm its accuracy and completeness, we commit and push these updates to our GitHub repository.

![](Figures\Screenshots\GitHub_related\workflow_yaml_file.png){fig-align="center"}
In the workflow of our project, we automate the data quality check, data ingestion into the database, and basic data analysis in the R script "Data_Validation_Import_Script.R", and the advanced data analysis in the R script "Advanced_Data_Analysis.R". Everytime new data files are added to the data folder in the local repository, the push request triggers actions including the validation of new data, updating the database with the cleaned new data, and automatically saving the visualizations produced by the advanced data analysis into the folder "Advanced_Data_Analysis".

![](Figures\Screenshots\GitHub_related\Actions.png){fig-align="center"}
There are a peek of some jobs that have been automatically triggered by the push request to be carried out in Actions, the workflow file under GitHub Actions is now operational, and it automatically executes the predefined tasks each time a change is made to the repository, without manual intervention.

# Part 4: Advanced Data Analysis and Reporting with Quarto in R

```{r}
## Access Existing Database
db_conn <- dbConnect(RSQLite::SQLite(), "Database/ecommerce.db")
```

**Product with Highest Sales:**
```{r}
top_5_products_sales <- dbGetQuery(db_conn, "SELECT
    od.product_id,
    p.product_name,
    ROUND(SUM(p.price),2) AS total_sales
FROM
    order_details od
JOIN
    product p ON od.product_id = p.product_id
GROUP BY
    od.product_id,
    p.product_name
ORDER BY
    total_sales DESC
LIMIT
    5;
")

ggplot(top_5_products_sales, aes(x = reorder(product_name, total_sales), y = total_sales)) +
  geom_col(width = 0.8) + 
  geom_text(aes(label = total_sales), vjust = 0.2, hjust=-0.1, position=position_dodge(width=0.9),size=3) +
  labs(x = "Product Name", y = "Total Sales") +
  theme_minimal() +
  coord_flip() + 
  ggtitle("Top 5 Products by Sales") +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5), legend.position = 'none')
```
Revealing the top 5 products by sales offers insights into customer preferences and product performance. It highlights the most popular products, indicating their demand and popularity in the market, and shows what the company should focus on selling to maximise revenue.

**Cities With Highest Sales:**
```{r}
cities_highest_sales <- dbGetQuery(db_conn,"SELECT
    a.city,
    ROUND(SUM(p.price),2) AS total_sales
FROM
    order_details od
JOIN
    product p ON od.product_id = p.product_id
JOIN
    buyer b ON od.buyer_id = b.buyer_id
JOIN
    address a ON b.address_id = a.address_id
GROUP BY
    a.city
ORDER BY
    total_sales DESC
LIMIT
    5;
")

ggplot(cities_highest_sales, aes(x = city, y = total_sales)) +
  geom_bar(stat = "identity", width = 0.5) +
  geom_text(aes(label = total_sales), vjust = -0.3, hjust=0.5, position=position_dodge(width=0.9),size=3) +
  labs(x = "City", y = "Total Sales") +
  theme_minimal() +
  ggtitle("City with Highest Sales") +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5), legend.position = 'none')
```


Analysing sales per city reveals the geographical distribution of product demand. Understanding where products sell best helps in targeting marketing efforts and optimising distribution strategies towards these cities. It helps in assessing market penetration and identifying areas for expansion.

**Promotion for Top 5 Products:**
```{r}
promotion_data <- dbGetQuery(db_conn, "SELECT * FROM promotion;")
top_5_products_promotion <- dbGetQuery(db_conn, "SELECT
    od.product_id,
    p.product_name,
    p.promotion_id,
    pm.status,
    ROUND(SUM(p.price),2) AS total_sales
FROM
    order_details od
JOIN
    product p ON od.product_id = p.product_id
JOIN 
    promotion pm ON p.promotion_id = pm.promotion_id
GROUP BY
    od.product_id,
    p.product_name
ORDER BY
    total_sales DESC
LIMIT
    5;
")

ggplot(top_5_products_promotion, aes(x = reorder(product_name, total_sales), y = total_sales, fill = status)) +
  geom_col(width = 0.8) + 
  labs(title = "Top 5 Products by Sales", x = "Product Name", y = "Total Sales") +
  theme_minimal() +
  #scale_fill_viridis_d() +
  coord_flip() + 
  scale_fill_discrete(name = "Promotion Status") + 
  ggtitle("Promotion Status of Top 5 products with respect to Sales") +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5), legend.position = 'right') 
```


Evaluating promotion status for the top 5 products provides insights into marketing effectiveness. Correlating sales with promotion status helps allocate resources of time and money efficiently towards marketing strategies and maximise sales outcomes.

**Number of Days Promotions are Running:**

```{r}
no_of_days_promotions <- mutate(promotion_data,
                         start_date = as.Date(start_date,format= "%Y-%m-%d", origin="1970-01-01"),
                         end_date = as.Date(end_date,format= "%Y-%m-%d", origin="1970-01-01"),
                         num_days_promotion = end_date - start_date) %>%
  filter(status == 'active')
no_of_days_promotions <- no_of_days_promotions %>%
  arrange(desc(num_days_promotion))

no_of_days_promotions <- no_of_days_promotions %>% 
  group_by(num_days_promotion) %>% 
  summarise(num_promotions = n()) %>%
  arrange((num_days_promotion))

ggplot(no_of_days_promotions, aes(x = num_days_promotion, y = num_promotions)) +
  geom_col(colors='') + 
  labs(x = "Number of days promotion is running", y = "Number of promotions") +
  theme_minimal() +
  #scale_fill_viridis_d() +
  ggtitle("Number of Promotions running across each different duration") +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5), legend.position = 'none') 
```


Analysing the duration of active promotions helps measure their impact on sales and customer engagement. Understanding promotion duration assists in optimizing promotional activities for maximum effectiveness.

**Sales Trends:**

```{r}
order_details <- dbGetQuery(db_conn,"SELECT * FROM order_details")
order_details <- mutate(order_details,
                        order_dates = as.Date(order_dates,format= "%Y-%m-%d", origin="1970-01-01"))
product <- dbGetQuery(db_conn,"SELECT * FROM product")


# Viewing the results
sales_trend_data <- inner_join(order_details, product, 
           by = c("product_id")) 

sales_trend_data <- sales_trend_data %>%
  group_by(order_dates) %>% 
  summarise(total_sales = sum(price))


ggplot(sales_trend_data, aes(x = order_dates, y = total_sales)) +
  geom_line() + 
  labs(x = "Date", y = "Sales") +
  theme_minimal() +
  #scale_fill_viridis_d() +
  ggtitle("Sales Trend") +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5), legend.position = 'none') 
```


Analysing sales trends over time identifies patterns, peak sales periods, and seasonal impacts. This informs inventory management, timing of promotions or campaigns, and strategic decision-making.

**Products With Highest and Lowest Reviews:**
```{r}
top_5_products_reviews <- dbGetQuery(db_conn, "SELECT
    r.product_id,
    p.product_name,
    ROUND(AVG(r.review_score),2) AS avg_review_score
FROM
    review r
JOIN
    product p ON r.product_id = p.product_id
GROUP BY
    r.product_id,
    p.product_name
ORDER BY
    avg_review_score DESC
LIMIT
    5;
")

ggplot(top_5_products_reviews, aes(x = reorder(product_name, avg_review_score), y = avg_review_score)) +
  geom_col(show.legend = FALSE, width=0.8) + 
  geom_text(aes(label = avg_review_score), vjust = 0.2, hjust=-0., position=position_dodge(width=0.9),size=4) +
  coord_flip() + 
  labs(x = "Product Name", y = "Average Review Score") +
  theme_minimal() +
  #scale_fill_viridis_d() + 
  ggtitle("Top 5 Products by Average Review Score") +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5), legend.position = 'none') 
```

```{r}
lowest_5_products_reviews <- dbGetQuery(db_conn, "SELECT
    p.product_id,
    p.product_name,
    ROUND(AVG(r.review_score),2) AS average_review_score
FROM
    review r
JOIN
    product p ON r.product_id = p.product_id
GROUP BY
    p.product_id,
    p.product_name
ORDER BY
    average_review_score ASC
LIMIT
    5;
")

ggplot(lowest_5_products_reviews, aes(x = reorder(product_name, -average_review_score), y = average_review_score)) +
  geom_bar(stat = "identity", width = 0.7) +
  geom_text(aes(label = average_review_score), vjust = 0.2, hjust=-0.3, position=position_dodge(width=0.9),size=3) +
  labs(x = "Product", y = "Average Review Score") +
  theme_minimal() +
  coord_flip() +
  ggtitle("Products with Lowest Review Scores") +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5), legend.position = 'none')
```

Examining top and lowest reviewed products provides insights into customer preferences and areas for improvement. This feedback guides product development and enhances customer satisfaction.


**Customer Lifetime Value (CLV):**

```{r}
customer_lifetime_value <- dbGetQuery(db_conn, "SELECT
    buyer_id,
    ROUND(SUM(p.price),2) AS total_spent,
    COUNT(distinct order_id) AS number_of_orders,
    ROUND((SUM(p.price) / COUNT(distinct order_id)),2) AS average_order_value
FROM
    order_details od
JOIN
    product p ON od.product_id = p.product_id
GROUP BY
    buyer_id
ORDER BY
    total_spent DESC;
")

top_n_buyers <- head(customer_lifetime_value, 10) 
# Change 10 to the desired number of top buyers to display

ggplot(top_n_buyers, aes(x = reorder(buyer_id, -total_spent), y = total_spent)) +
  geom_bar(stat = "identity", width = 0.7) +
  labs(x = "Buyer ID", y = "Total Spent") +
  theme_minimal() +
  ggtitle("Top Buyers by Customer Lifetime Value") +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5), legend.position = 'none')
```


Calculating CLV helps identify top-valuable customers for targeted marketing and loyalty programs. Understanding customer value informs engagement strategies and maximixes profitability. Can guide engagement strategies, enhancing customer relationships and loyalty.

**Effectiveness of Promotions:**

```{r}
effective_promotions <- dbGetQuery(db_conn, "SELECT
    promo.promotion_type,
    COUNT(*) AS number_of_sales,
    ROUND(SUM(prod.price),2) AS total_revenue
FROM
    order_details od
JOIN
    product prod ON od.product_id = prod.product_id
JOIN
    promotion promo ON prod.promotion_id = promo.promotion_id
WHERE
    promo.status = 'active'
GROUP BY
    promo.promotion_type
ORDER BY
    total_revenue DESC;
")

ggplot(effective_promotions, aes(x = reorder(promotion_type, -total_revenue), y = total_revenue)) +
  geom_bar(stat = "identity", width=0.7) +
  geom_text(aes(label = total_revenue), vjust = -0.2, hjust=0.5, position=position_dodge(width=0.9),size=4) +
  labs(x = "Promotion Type", y = "Total Revenue") +
  theme_minimal() +
  ggtitle("Effectiveness of Promotions") +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5), legend.position = 'none')
```


Evaluating promotion performance by sales and revenue enhances campaign initiatives and resource allocation. Optimizing promotional activities maximixes return on investment.

**Most Reviewed Products:**
```{r}
most_reviewed_products <- dbGetQuery(db_conn,"SELECT
    p.product_name,
    COUNT(*) AS review_count,
    ROUND(AVG(r.review_score),2) AS avg_review_score
FROM
    review r
JOIN
    product p ON r.product_id = p.product_id
GROUP BY
    p.product_name
ORDER BY
    review_count DESC
LIMIT 10;
")

ggplot(most_reviewed_products, aes(x = reorder(product_name, -review_count), y = review_count)) +
  geom_bar(stat = "identity", width=0.7) +
  geom_text(aes(label = review_count), vjust = -0.2, hjust=0.5, position=position_dodge(width=0.9),size=4) +
  labs(x = "Product Name", y = "Number of Reviews") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ggtitle("Most Reviewed Products") +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5), legend.position = 'none')
```

Identifying the most reviewed products highlights customer engagement and product visibility. Products with many reviews often have better market presence and credibility, impacting brand reputation and customer trust.


# Conclusion

To conclude, this project not only demonstrated technical prowess in data management but also set a benchmark for future e-commerce database projects, emphasising the importance of a well-structured and analytically driven database design in the digital commerce landscape. Through four distinct stages, the project encapsulated the essence of database design, normalisation, data generation, and advanced data analysis to generate insights for thr company.
