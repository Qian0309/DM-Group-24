---
title: "IB9HP0 Data Management"
author: "Group 24"
output: pdf_document
number_sections: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

install.packages("RSQLite")
install.packages("dplyr")
install.packages("ggplot2")
install.packages("knitr")

library(knitr)
library(RSQLite)
library(dplyr)
library(ggplot2)
```

# Introduction

In this project, we developed a UK-based e-commerce database for IT products, without international shipping. The project unfolds in four stages, each enhancing our platform's development and comprehension.

# Section 1: Database Design and Implementation

## Section 1.1: E-R Diagram Design and Relationship Sets

The platform adheres to an annual promotion policy and uses a "Product_ID" system based on "Supplier_ID," limiting suppliers to a unique ID per product. It also handles payment collection and subsequent distribution to suppliers. It involves 7 entities.

1)  Buyer: Customers creating accouns to order on the platform.

2)  Supplier: Sellers registering to list products.

3)  Product: Available products for purchase.

4)  Transaction: Customers' product orders.

5)  Promotion: Product discounts to entice customers.

6)  Shipper: Shipper information.

7)  Reviews: Customer feedback post-product receipt.

The E-R diagram below illustrates the e-commerce database pre-normalisation.

![](Figures\Screenshots\ERD\ERD_before_normalization.png){fig-align="center"}

## Section 1.2: SQL Database Schema Creation

The conceptual schema outlined in Section 1.1 is converted into a logical schema after normalisation, using the following steps:

* 1NF: Multi-valued attributes include 'Buyer_Address','Supplier_Address', and 'Dimensions' in the Product entity that must be normalised. An Address table with 'address_id', 'house_number', 'house_name', 'street', 'city', 'county', and 'post_code' is introduced. This table connects to Buyer and Supplier entities through 'address_id' as a foreign key, establishing 1:1 relationships. A separate Dimensions entity is also created, linked to the Product entity with a 1:1 relationship.

* 2NF: The Product and Buyer entities have an M:N relationship, which violates 2NF due to functional dependencies where many products can be bought by a single buyer and vice versa, creating duplicate entries of the primary key attribute in each table. An 'order_details' table resolves this, by storing 'product_id' and 'buyer_id' as composite primary keys, with 'order_id' as its primary key.

* 3NF: The logical schema ensures attributes directly depend on their table's primary key, with no transitive dependencies.

### Conceputual E-R Diagram of the Database after Normalisation

![](Figures\Screenshots\ERD\ERD_after_normalization.png){fig-align="center"}

### Logical Schema of the Database after Normalisation

* product(product _id, product _name, product _description, weight, price, promotion_id, dimension_id , supplier_id) 

* promotion(promotion_id, promotion_type, start_date, end_date, status) 

* buyer(buyer_id, first_name, last_name, date_of_birth, address_id) 

* supplier(Supplier_ID, Supplier_Name, Supplier_Type, Contract_Type, Number_of_year_of_association, address_id) 

* review(review_id, review_score, review_description, product_id, buyer_id) 

* payment(payment_id, payment_type, payment_amount, installment_number, order_id) 

* shipper(Shipper_ID, Shipper_Name, Service, Fixed Price, Cost_per_mile) 

* order_details(order_id, product_id, buyer_id, supplier_id, order_dates, shipper_id) 

* address(address_id, house_number, house_name, street, city, county, post_code) 

* dimension(Dimension_ID, Length, Width, Height) 

### Relationship Sets after Normalisation

We've mapped out the interactions between entities in our e-commerce database through relationship sets.

1)  Buyer and Address (1:1):

![](Figures\Screenshots\relationship_set\buyer_address(1_1).png){fig-align="center"}

Indicating that each buyer has one address, and each address is associated with one buyer.

2)  Buyer and Order Details (1:N):

![](Figures\Screenshots\relationship_set\buyer_order(1_n).png){fig-align="center"}

Indicating a buyer can place multiple orders, with each 'order detail' linked to a single buyer.

3)  Buyer and Reviews (1:N):

![](Figures\Screenshots\relationship_set\buyer_review(1_n).png){fig-align="center"}

Meaning a buyer can submit multiple reviews, with each review associated with that buyer.

4)  Order Details and Payment (1:N):

![](Figures\Screenshots\relationship_set\order_payment(1_n).png){fig-align="center"}

Meaning each order detail can involve multiple transactions, with each transaction corresponding to a specific order detail.

5)  Product to Dimension (1:1):

![](Figures\Screenshots\relationship_set\product_dimension(1_1).png){fig-align="center"}

Indicating each product has a unique set of dimensions, with each set of dimensions tied to a single product.

6)  Product to Order Details (1:N):

![](Figures\Screenshots\relationship_set\product_order(1_n).png){fig-align="center"}

Meaning that one product can be present in many order details. Conversely, each order detail is associated with only one product, indicating a specific product is selected for each order.

7)  Product to Promotion (N:1):

![](Figures\Screenshots\relationship_set\Product_Promotion(n_1).png){fig-align="center"}

Indicating that multiple products can be part of the same promotion. Conversely, each promotion can apply to multiple products.

8)  Product to Review (1:N):

![](Figures\Screenshots\relationship_set\Product_Review(1_n).png){fig-align="center"}

Showing that each product can have multiple reviews written about it. Conversely, each review is associated with one product, indicating that customersâ€™ feedback is specific to a particular product

9)  Supplier and Order Details (1:N):

![](Figures\Screenshots\relationship_set\shipper_order(1_n).png){fig-align="center"}

Showing that a single supplier can be connected to multiple order details, with each order detail relating to only one supplier.

10) Supplier and Address (1:1):

![](Figures\Screenshots\relationship_set\supplier_address(1_1).png){fig-align="center"}

Each supplier is tied to a single address, and each address is linked to a specific supplier

11) Supplier and Order Details (1:N):

![](Figures\Screenshots\relationship_set\supplier_order(1_n).png){fig-align="center"}

Showing that a single supplier can be connected to multiple order details, with each order detail relating to only one supplier.

12) Supplier and Product (1:N):

![](Figures\Screenshots\relationship_set\supplier_product(1_n).png){fig-align="center"}

Indicating that a supplier sells many products. One supplier can be linked to multiple 'product' entities.

### Physical Schema of the Database

We're ready to convert the E-R diagram into a normalised SQL database schema (3NF), complete with defined tables, data types, constraints, and key relationships.

#### Table Description for Promotions

```{r}
# Define the table data
promotion_table <- data.frame(
  `Field Name` = c("promotion_id", "promotion_type", "start_date", "end_date", "status"),
  `Data Type` = c("VARCHAR(50)", "VARCHAR(50)", "DATE", "DATE", "VARCHAR(50)"),
  `Constraints` = c("PRIMARY KEY", "", "", "", ""),
  `Description` = c("Unique identifier for promotion", "Type of promotion", "Promotion start date", "Promotion end date", "Status of the promotion")
)

# Create the table
kable(promotion_table, caption = "Table Description for Promotions", align = 'l')
```

This automatic indexing on primary keys as the first column allows for quick searches, insertions, and ensures uniqueness, enhancing query performance significantly. Indexing foreign key columns as the second key is crucial for enhancing the performance of join operations between tables

For other columns without explicit indexing, queries that search or filter by these fields may perform a full table scan, which is slower.

#### Table Description for Shippers

```{r}
# Define the table data for the shipper table
shipper_table <- data.frame(
  `Field Name` = c("shipper_id", "shipper_name", "service", "fixed_price", "cost_per_mile"),
  `Data Type` = c("VARCHAR(50)", "VARCHAR(50)", "VARCHAR(100)", "DOUBLE", "DOUBLE"),
  `Constraints` = c("PRIMARY KEY", "", "", "", ""),
  `Description` = c("Unique identifier for the shipper", 
                    "Name of the shipper", 
                    "Type of service offered by the shipper", 
                    "Fixed price for the service", 
                    "Cost per mile for the service")
)

# Create the table
kable(shipper_table, caption = "Table Description for Shippers", align = 'l')
```

#### Table Description for Address

```{r}

address_table <- data.frame(
  `Field Name` = c("address_id", "house_number", "house_name", "street", "city", "county", "post_code"),
  `Data Type` = c("VARCHAR(50)", "INT", "VARCHAR(50)", "VARCHAR(50)", "VARCHAR(20)", "VARCHAR(20)", "VARCHAR(10)"),
  `Constraints` = c("PRIMARY KEY", "", "", "", "NOT NULL", "", ""),
  `Description` = c("Unique identifier for the address", 
                    "Number of the house", 
                    "Name of the house if applicable", 
                    "Street name", 
                    "City name", 
                    "County name", 
                    "Postal code of the address")
)

# Create the table
kable(address_table, caption = "Table Description for Addresses", align = 'l')

```

#### Table Description for Dimensions

```{r}
# Define the table data for the dimension table
dimension_table <- data.frame(
  `Field Name` = c("dimension_id", "length", "width", "height"),
  `Data Type` = c("VARCHAR(50)", "DOUBLE", "DOUBLE", "DOUBLE"),
  `Constraints` = c("PRIMARY KEY", "", "", ""),
  `Description` = c("Unique identifier for the dimension record", 
                    "Length measurement", 
                    "Width measurement", 
                    "Height measurement")
)

# Create the table
kable(dimension_table, caption = "Table Description for Dimensions", align = 'l')

```

#### Table Description for Buyers

```{r}
buyer_table <- data.frame(
  `Field Name` = c("buyer_id", "first_name", "last_name", "date_of_birth", "address_id"),
  `Data Type` = c("VARCHAR(50)", "VARCHAR(250)", "VARCHAR(250)", "DATE", "VARCHAR(50)"),
  `Constraints` = c("PRIMARY KEY", "NOT NULL", "", "", "NOT NULL, FOREIGN KEY references address(address_id)"),
  `Description` = c("Unique identifier for the buyer", 
                    "First name of the buyer. Mandatory field.", 
                    "Last name of the buyer", 
                    "Date of birth of the buyer", 
                    "Reference to the buyer's address, must exist in the `address` table. This field is mandatory and establishes a foreign key relationship with the `address` table.")
)

# Create the table
kable(buyer_table, caption = "Table Description for Buyers", align = 'l')

```

#### Table Description for Suppliers

```{r}
# Load the knitr package for kable()

supplier_table <- data.frame(
  `Field Name` = c("supplier_id", "supplier_type", "contract_type", "number_of_year_of_association", "supplier_name", "address_id"),
  `Data Type` = c("VARCHAR(50)", "VARCHAR(250)", "VARCHAR(250)", "INT", "VARCHAR(50)", "VARCHAR(50)"),
  `Constraints` = c("PRIMARY KEY", "", "", "", "", "NOT NULL, FOREIGN KEY references address(address_id)"),
  `Description` = c("Unique identifier for the supplier", 
                    "Type of supplier (e.g., goods, services)", 
                    "Type of contract with the supplier", 
                    "Number of years the supplier has been associated with", 
                    "Name of the supplier", 
                    "Reference to the supplier's address, must exist in the `address` table. This field is mandatory and establishes a foreign key relationship with the `address` table.")
)

# Create the table
kable(supplier_table, caption = "Table Description for Suppliers", align = 'l')

```

#### Table Description for Products

```{r}
product_table <- data.frame(
  `Field Name` = c("product_id", "product_name", "product_description", "weight", "price", "promotion_id", "supplier_id", "dimension_id"),
  `Data Type` = c("VARCHAR(50)", "VARCHAR(250)", "VARCHAR(250)", "DOUBLE", "DOUBLE", "VARCHAR(50)", "VARCHAR(50)", "VARCHAR(50)"),
  `Constraints` = c("PRIMARY KEY", "", "", "", "", "NOT NULL, FOREIGN KEY references promotion(promotion_id)", "NOT NULL, FOREIGN KEY references supplier(supplier_id)", "NOT NULL, FOREIGN KEY references dimension(dimension_id)"),
  `Description` = c("Unique identifier for the product", 
                    "Name of the product", 
                    "Description of the product", 
                    "Weight of the product", 
                    "Price of the product", 
                    "Associated promotion ID, linking to the promotion table", 
                    "Associated supplier ID, linking to the supplier table", 
                    "Associated dimension ID, linking to the dimension table")
)

kable(product_table, caption = "Table Description for Products", align = 'l')

```

#### Table Description for Reviews

```{r}
review_table <- data.frame(
  `Field Name` = c("review_id", "buyer_id", "product_id", "review_score", "review_description"),
  `Data Type` = c("VARCHAR(50)", "VARCHAR(250)", "VARCHAR(250)", "DOUBLE", "VARCHAR(250)"),
  `Constraints` = c("PRIMARY KEY", "NOT NULL, FOREIGN KEY references buyer(buyer_id)", "NOT NULL, FOREIGN KEY references product(product_id)", "", ""),
  `Description` = c("Unique identifier for the review", 
                    "Associated buyer ID, linking to the buyer table", 
                    "Associated product ID, linking to the product table", 
                    "Numerical score of the review", 
                    "Textual description of the review")
)

kable(review_table, caption = "Table Description for Reviews", align = 'l')
```

#### Table Description for Order Details

```{r}
# Define the table data for the order_details table, including foreign key details within the table
order_details_table <- data.frame(
  `Field Name` = c("order_id", "product_id", "buyer_id", "supplier_id", "order_dates", "shipper_id"),
  `Data Type` = c("VARCHAR(50)", "VARCHAR(50)", "VARCHAR(50)", "VARCHAR(50)", "DATE", "VARCHAR(50)"),
  `Constraints` = c("PRIMARY KEY", "NOT NULL, FOREIGN KEY references product(product_id)", "NOT NULL, FOREIGN KEY references buyer(buyer_id)", "NOT NULL, FOREIGN KEY references supplier(supplier_id)", "", "NOT NULL, FOREIGN KEY references shipper(shipper_id)"),
  `Description` = c("Unique identifier for the order", 
                    "Associated product ID, linking to the product table", 
                    "Associated buyer ID, linking to the buyer table", 
                    "Associated supplier ID, linking to the supplier table", 
                    "Date of the order", 
                    "Associated shipper ID, linking to the shipper table")
)

kable(order_details_table, caption = "Table Description for Order Details", align = 'l')

```

#### Table Description for Payments

```{r}
payment_table <- data.frame(
  `Field Name` = c("payment_id", "payment_type", "payment_amount", "installment_number", "order_id"),
  `Data Type` = c("VARCHAR(50)", "VARCHAR(250)", "DOUBLE", "INT", "VARCHAR(50)"),
  `Constraints` = c("PRIMARY KEY", "", "", "", "NOT NULL, FOREIGN KEY references order_details(order_id)"),
  `Description` = c("Unique identifier for the payment", 
                    "Type of payment (e.g., credit card, PayPal)", 
                    "Total amount of the payment", 
                    "If applicable, the number of the installment", 
                    "Associated order ID, linking to the order_details table")
)
kable(payment_table, caption = "Table Description for Payments", align = 'l')
```

# Section 2: Data Generation and Management

## Section 2.1: Synthetic Data Generation

We synthesised data with R, Mockaroo, and Excel to simulate a dataset that closely mimics real-world scenarios.

* Mockaroo provided realistic addresses, emails, and name for several entities

* R scripts modeled data distributions, focusing on product and promotion characteristics, IDs, and date related attributes to capture real variability and complexity

* After importing the data from R and Mockaroo, the foreign keys were combined in Excel, using â€˜Randbwteenâ€™ to ensure that the inter-entity relationships are accurately represented.

We produced four data splits for ingestion validation, incorporating flawed entries in the final two to test our validation protocols.

## Section 2.2: Data Import and Quality Assurance

The synthetic data, generated in .csv format, is imported. The data undergoes various integrity and validation checks, detailed below:

### Data Integrity:

1) Primary Key fields:

No NA/NULL values are allowed in the primary key attributes of any entities. The primary key ID must follow the format specified in Section 2.1.

2) Date fields:

No future dates should appear in any date field. This includes the Date of Birth of buyers and Order dates.

3) Product entity:

The weight of the product must not exceed 100 pounds

4) Promotion entity:

The end date of a promotion must be later than its start date.

5) Review entity:

Review scores must not exceed 10.

6) Address entity:

Length of postcode should be only 5 or 6 characters in accordance with postcode of UK residents.

7) Dimension entity:

The Length, Width, and Height of a product must not exceed 150 cm.

8) Non-Negativity:

All numeric attributes of float or integer type must not have negative values. This includes Weight, Price, Years of Association, Review Score, Payment Value, Installment Number, Fixed Price, Cost per Mile, Length, Width, Height, and House Number.

### Referential Integrity :

Referential integrity checks are conducted for all relationships discussed in Section 1.1. For example, in the Product to Review (1:N) relationship, the Review entity's Product_ID, serving as a foreign key, indicates a specific product's review in the E-commerce system. Referential integrity ensures no review is entered for a product not present in the system. To validate, unique Product_ID keys from the Review table are compared with those from the Product table; the difference should be NULL or 0. A non-zero value indicates the presence of a Product_ID in the Review table that doesn't match any in the Product table, violating referential integrity. Such records are removed from the Review table.

# Section 3: Data Pipeline Generation

## Section 3.1: GitHub Repository and Workflow Setup

![](Figures\Screenshots\GitHub_related\GitHub_Repo.png){fig-align="center"}
To allow group members to collaborate on the project simultaneously we have adopted the use of a remote repository on GitHub. This online platform serves as a centralised storage for our project's history, enabling efficient management and version control.

![](Figures\Screenshots\GitHub_related\repo_url.png){fig-align="center"}
Integrating our project with Posit Cloud, we used the HTTPS clone URL from GitHub to establish a connection between our local and remote repositories directly within Posit Cloud. This integration streamlined our workflow by providing a centralised platform for development, enabling efficient access and management of the project's codebase.

![](Figures\Screenshots\GitHub_related\commit_push_pull.png){fig-align="center"}
To streamline our project management and enhance version control among team members, we utilised commit, push, and pull operations effectively. By committing changes before pushing, we enabled team members to save the state of our project at specific points following any modifications made in our local repositories. This process not only enables detailed tracking of who made specific changes and why, but also ensures that each contribution is reviewed before being shared with the team.

Pushing these commits to the remote repository then publishes each member's contributions, ensuring everyone is working on the most updated version. Regularly pulling updates from the remote repository is crucial for keeping our local copies current,  reducing the likelihood of merge conflicts between the local and remote version after changes are made.

![](Figures\Screenshots\GitHub_related\working_log.png){fig-align="center"}

## Section 3.2: GitHub Actions for Continuous Integration

GitHub Workflows automate processes within a repository using YAML files. We started by creating a `.github/workflows/` directory to house our workflow files. Then, we added a file named "ETL workflow for group24" within this directory to outline our specific automated tasks, focusing on the Extract, Transform, Load (ETL) processes crucial to our project's data handling needs, enhancing efficiency.

The workflow of our project is shown in the screenshot below

![](Figures\Screenshots\GitHub_related\workflow.png){fig-align="center"}

In this phase of configuring our GitHub Workflow, we set the trigger condition to activate on every push event to the repository. This configuration ensures that any time changes are pushed or a pull request is merged, the workflow initiates automatically. Following a thorough review of the code to confirm its accuracy and completeness, we commit and push these updates to our GitHub repository.

![](Figures\Screenshots\GitHub_related\workflow_yaml_file.png){fig-align="center"}
In the workflow of our project, we automate the data quality check, data ingestion into the database, and basic data analysis in the R script "Data_Validation_Import_Script.R", and the advanced data analysis in the R script "Advanced_Data_Analysis.R". Everytime new data files are added to the data folder in the local repository, the push request triggers actions including the validation of new data, updating the database with the cleaned new data, and automatically saving the visualizations produced by the advanced data analysis into the folder "Advanced_Data_Analysis".

![](Figures\Screenshots\GitHub_related\bad_data_detected.png){fig-align="center"}

As shown in the screenshot above, there are some data did not pass the validation checks and are excluded from ingestions.

![](Figures\Screenshots\GitHub_related\Actions.png){fig-align="center"}
We use a GitHub remote repository to enable simultaneous team collaboration, providing a centralised project history for effective management and version control.


# Section 4: Advanced Data Analysis and Reporting with Quarto in R

```{r}
## Access Existing Database
db_conn <- dbConnect(RSQLite::SQLite(), "Database/ecommerce.db")
```

**Top 5 Products with Highest Sales:**
```{r fig.height = 3, fig.width=9}
top_5_products_sales <- dbGetQuery(db_conn, "SELECT
    od.product_id,
    p.product_name,
    ROUND(SUM(p.price),2) AS total_sales
FROM
    order_details od
JOIN
    product p ON od.product_id = p.product_id
GROUP BY
    od.product_id,
    p.product_name
ORDER BY
    total_sales DESC
LIMIT
    5;
")

ggplot(top_5_products_sales, aes(x = reorder(product_name, total_sales), y = total_sales)) +
  geom_col(width = 0.8) + 
  geom_text(aes(label = (total_sales)), vjust = 0.3, hjust=-0.1, position=position_dodge(width=0.9),size=3) +
  labs(x = "Product Name", y = "Total Sales") +
  theme_minimal() +
  coord_flip() + 
  ggtitle("Top 5 Products by Sales") +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5), legend.position = 'none')
```
This offers insights into customer preferences and product performance. It unveils market trends and successful products, guiding the company to capitalize on these revenue drivers.

**Top 5 Cities With Highest Sales:**
```{r}
cities_highest_sales <- dbGetQuery(db_conn,"SELECT
    a.city,
    ROUND(SUM(p.price),2) AS total_sales
FROM
    order_details od
JOIN
    product p ON od.product_id = p.product_id
JOIN
    buyer b ON od.buyer_id = b.buyer_id
JOIN
    address a ON b.address_id = a.address_id
GROUP BY
    a.city
ORDER BY
    total_sales DESC
LIMIT
    5;
")

ggplot(cities_highest_sales, aes(x = city, y = total_sales)) +
  geom_bar(stat = "identity", width = 0.5) +
  geom_text(aes(label = total_sales), vjust = -0.3, hjust=0.5, position=position_dodge(width=0.9),size=3) +
  labs(x = "City", y = "Total Sales") +
  theme_minimal() +
  ggtitle("City with Highest Sales") +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5), legend.position = 'none')
```


Determines where demand is highest, informs targeted marketing and distribution optimisation, and identifies market reach and potential growth areas.

**Promotion for Top 5 Products:**
```{r}
promotion_data <- dbGetQuery(db_conn, "SELECT * FROM promotion;")
top_5_products_promotion <- dbGetQuery(db_conn, "SELECT
    od.product_id,
    p.product_name,
    p.promotion_id,
    pm.status,
    ROUND(SUM(p.price),2) AS total_sales
FROM
    order_details od
JOIN
    product p ON od.product_id = p.product_id
JOIN 
    promotion pm ON p.promotion_id = pm.promotion_id
GROUP BY
    od.product_id,
    p.product_name
ORDER BY
    total_sales DESC
LIMIT
    5;
")

ggplot(top_5_products_promotion, aes(x = reorder(product_name, total_sales), y = total_sales, fill = status)) +
  geom_col(width = 0.8) + 
  labs(title = "Top 5 Products by Sales", x = "Product Name", y = "Total Sales") +
  theme_minimal() +
  #scale_fill_viridis_d() +
  coord_flip() + 
  scale_fill_discrete(name = "Promotion Status") + 
  ggtitle("Promotion Status of Top 5 products with respect to Sales") +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5), legend.position = 'right') 
```

Assesses marketing success for top products and guides allocation of resources such as time and money for optimal sales results.

**Number of Days Promotions are Running:**

```{r}
no_of_days_promotions <- mutate(promotion_data,
                         start_date = as.Date(start_date,format= "%Y-%m-%d", origin="1970-01-01"),
                         end_date = as.Date(end_date,format= "%Y-%m-%d", origin="1970-01-01"),
                         num_days_promotion = end_date - start_date) %>%
  filter(status == 'active')
no_of_days_promotions <- no_of_days_promotions %>%
  arrange(desc(num_days_promotion))

no_of_days_promotions <- no_of_days_promotions %>% 
  group_by(num_days_promotion) %>% 
  summarise(num_promotions = n()) %>%
  arrange((num_days_promotion))

ggplot(no_of_days_promotions, aes(x = num_days_promotion, y = num_promotions)) +
  geom_col(colors='') + 
  labs(x = "Number of days promotion is running", y = "Number of promotions") +
  theme_minimal() +
  #scale_fill_viridis_d() +
  ggtitle("Number of Promotions running across each different duration") +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5), legend.position = 'none') 
```

Gauges sales impact and customer response, aiding in fine-tuning promotion timing for peak efficacy.

**Sales Trends:**

```{r}
order_details <- dbGetQuery(db_conn,"SELECT * FROM order_details")
order_details <- mutate(order_details,
                        order_dates = as.Date(order_dates,format= "%Y-%m-%d", origin="1970-01-01"))
product <- dbGetQuery(db_conn,"SELECT * FROM product")


# Viewing the results
sales_trend_data <- inner_join(order_details, product, 
           by = c("product_id")) 

sales_trend_data <- sales_trend_data %>%
  group_by(order_dates) %>% 
  summarise(total_sales = sum(price))


ggplot(sales_trend_data, aes(x = order_dates, y = total_sales)) +
  geom_line() + 
  labs(x = "Date", y = "Sales") +
  theme_minimal() +
  #scale_fill_viridis_d() +
  ggtitle("Sales Trend") +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5), legend.position = 'none') 
```

Detects patterns, peak sales periods and seasonal influences to guide inventory management, promotion timings, and strategy.

**Products With Highest and Lowest Reviews:**
```{r}
top_5_products_reviews <- dbGetQuery(db_conn, "SELECT
    r.product_id,
    p.product_name,
    ROUND(AVG(r.review_score),2) AS avg_review_score
FROM
    review r
JOIN
    product p ON r.product_id = p.product_id
GROUP BY
    r.product_id,
    p.product_name
ORDER BY
    avg_review_score DESC
LIMIT
    5;
")

ggplot(top_5_products_reviews, aes(x = reorder(product_name, avg_review_score), y = avg_review_score)) +
  geom_col(show.legend = FALSE, width=0.8) + 
  geom_text(aes(label = avg_review_score), vjust = 0.2, hjust=-0., position=position_dodge(width=0.9),size=4) +
  coord_flip() + 
  labs(x = "Product Name", y = "Average Review Score") +
  theme_minimal() +
  #scale_fill_viridis_d() + 
  ggtitle("Top 5 Products by Average Review Score") +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5), legend.position = 'none') 
```

```{r}
lowest_5_products_reviews <- dbGetQuery(db_conn, "SELECT
    p.product_id,
    p.product_name,
    ROUND(AVG(r.review_score),2) AS average_review_score
FROM
    review r
JOIN
    product p ON r.product_id = p.product_id
GROUP BY
    p.product_id,
    p.product_name
ORDER BY
    average_review_score ASC
LIMIT
    5;
")

ggplot(lowest_5_products_reviews, aes(x = reorder(product_name, -average_review_score), y = average_review_score)) +
  geom_bar(stat = "identity", width = 0.7) +
  geom_text(aes(label = average_review_score), vjust = 0.2, hjust=-0.3, position=position_dodge(width=0.9),size=3) +
  labs(x = "Product", y = "Average Review Score") +
  theme_minimal() +
  coord_flip() +
  ggtitle("Products with Lowest Review Scores") +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5), legend.position = 'none')
```

Examining top and lowest reviewed products highlights customer tastes and improvement areas, shaping product refinement and boosting satisfaction.


**Customer Lifetime Value (CLV):**

```{r}
customer_lifetime_value <- dbGetQuery(db_conn, "SELECT
    buyer_id,
    ROUND(SUM(p.price),2) AS total_spent,
    COUNT(distinct order_id) AS number_of_orders,
    ROUND((SUM(p.price) / COUNT(distinct order_id)),2) AS average_order_value
FROM
    order_details od
JOIN
    product p ON od.product_id = p.product_id
GROUP BY
    buyer_id
ORDER BY
    total_spent DESC;
")

top_n_buyers <- head(customer_lifetime_value, 10) 
# Change 10 to the desired number of top buyers to display

ggplot(top_n_buyers, aes(x = reorder(buyer_id, -total_spent), y = total_spent)) +
  geom_bar(stat = "identity", width = 0.7) +
  labs(x = "Buyer ID", y = "Total Spent") +
  theme_minimal() +
  ggtitle("Top Buyers by Customer Lifetime Value") +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5), legend.position = 'none')
```

Pinpoints high-value customers for targeted marketing and engagement strategies, and loyalty initiatives, fostering relationships and maximising profits.

**Effectiveness of Promotions:**

```{r}
effective_promotions <- dbGetQuery(db_conn, "SELECT
    promo.promotion_type,
    COUNT(*) AS number_of_sales,
    ROUND(SUM(prod.price),2) AS total_revenue
FROM
    order_details od
JOIN
    product prod ON od.product_id = prod.product_id
JOIN
    promotion promo ON prod.promotion_id = promo.promotion_id
WHERE
    promo.status = 'active'
GROUP BY
    promo.promotion_type
ORDER BY
    total_revenue DESC;
")

ggplot(effective_promotions, aes(x = reorder(promotion_type, -total_revenue), y = total_revenue)) +
  geom_bar(stat = "identity", width=0.7) +
  geom_text(aes(label = total_revenue), vjust = -0.2, hjust=0.5, position=position_dodge(width=0.9),size=4) +
  labs(x = "Promotion Type", y = "Total Revenue") +
  theme_minimal() +
  ggtitle("Effectiveness of Promotions") +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5), legend.position = 'none')
```


Improves campaign initiatives and resource investment by analysing sales and revenue, ensuring optimal return on investment.

**Most Reviewed Products:**
```{r}
most_reviewed_products <- dbGetQuery(db_conn,"SELECT
    p.product_name,
    COUNT(*) AS review_count,
    ROUND(AVG(r.review_score),2) AS avg_review_score
FROM
    review r
JOIN
    product p ON r.product_id = p.product_id
GROUP BY
    p.product_name
ORDER BY
    review_count DESC
LIMIT 10;
")

ggplot(most_reviewed_products, aes(x = reorder(product_name, -review_count), y = review_count)) +
  geom_bar(stat = "identity", width=0.7) +
  geom_text(aes(label = review_count), vjust = -0.2, hjust=0.5, position=position_dodge(width=0.9),size=4) +
  labs(x = "Product Name", y = "Number of Reviews") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ggtitle("Most Reviewed Products") +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5), legend.position = 'none')
```

Showcases customer interaction and market visibility, with highly reviewed products often having better market presence and credibility, impacting brand reputation and customer trust.


# Conclusion

In summary, this project showcased a technical blueprint for data management and set a standard for future e-commerce databases by highlighting the critical role of structured and data-driven design. It encompassed four key phasesâ€”design and normalisation, synthetic data creation, workflow management and in-depth analysisâ€”providing valuable insights for e-commerce systems.


# Appendix

1. See our GitHub repository via this link: https://github.com/Qian0309/DM-Group-24